{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Motivating Example\n",
    "\n",
    "Before we could begin writing, the authors of this book,\n",
    "like much of the work force, had to become caffeinated.\n",
    "We hopped in the car and started driving.\n",
    "Using an iPhone, Alex called out 'Hey Siri',\n",
    "awakening the phone's voice recognition system.\n",
    "Then Mu commanded 'directions to Blue Bottle coffee shop'.\n",
    "The phone quickly displayed the transcription of his command.\n",
    "It also recognized that we were asking for directions\n",
    "and launched the Maps application to fulfill our request.\n",
    "Once launched, the Maps app identified a number of routes.\n",
    "Next to each route, the phone displayed a predicted transit time.\n",
    "While we fabricated this story for pedagogical convenience,\n",
    "it demonstrates that in the span of just a few seconds,\n",
    "our everyday interactions with a smartphone\n",
    "can engage several machine learning models.\n",
    "\n",
    "<!-- If you've never worked with machine learning before, you might be\n",
    "wondering what we're talking about.  You might ask, 'isn't that just\n",
    "programming?' or 'what does *machine learning* even mean?'  First, to\n",
    "be clear, we implement all machine learning algorithms by writing\n",
    "computer programs.  Indeed, we use the same languages and hardware as\n",
    "other fields of computer science, but not all computer programs\n",
    "involve machine learning.  In response to the second question,\n",
    "precisely defining a field of study as vast as machine learning is\n",
    "hard.  It's a bit like answering, 'what is math?'.  But we'll try to\n",
    "give you enough intuition to get started. -->\n",
    "\n",
    "<!--\n",
    "Consider the growing ecosystem of voice assistants\n",
    "powering most smartphones and home speakers like\n",
    "Amazon's Echo, Google's Home, and Apple's HomePod.\n",
    "The first step in any interaction with these devices typically\n",
    "involves triggering them with a \"wake\n",
    "word\" like “Alexa”, “Okay, Google” or “Siri”. -->\n",
    "\n",
    "Imagine just writing a program to respond to a *wake word*\n",
    "like 'Alexa', 'Okay, Google' or 'Siri'.\n",
    "Try coding it up in a room by yourself\n",
    "with nothing but a computer and a code editor.\n",
    "How would you write such a program from first principles?\n",
    "Think about it... the problem is hard.\n",
    "Every second, the microphone will collect roughly 44,000 samples.\n",
    "What rule could map reliably from a snippet of raw audio\n",
    "to confident predictions ``{yes, no}``\n",
    "on whether the snippet contains the wake word?\n",
    "If you're stuck, don't worry.\n",
    "We don't know how to write such a program from scratch either.\n",
    "That's why we use ML.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/d2l-ai/notebooks/master/img/wake-word.png\" alt=\"\" width=293 height=49/>\n",
    "\n",
    "\n",
    "Here's the trick.\n",
    "Often, even when we don't know how to tell a computer\n",
    "explicitly how to map from inputs to outputs,\n",
    "we are nonetheless capable of performing the cognitive feat ourselves.\n",
    "In other words, even if you don't know *how to program a computer*\n",
    "to recognize the word 'Alexa',\n",
    "you yourself *are able* to recognize the word 'Alexa'.\n",
    "Armed with this ability,\n",
    "we can collect a huge *dataset* containing examples of audio\n",
    "and label those that *do* and that *do not* contain the wake word.\n",
    "In the ML approach, we do not design a system *explicitly*\n",
    "to recognize wake words.\n",
    "Instead, we define a flexible program\n",
    "whose behavior is determined by a number of *parameters*.\n",
    "Then we use the dataset to determine\n",
    "the best possible set of parameters,\n",
    "those that improve the performance of our program\n",
    "with respect to some measure of performance on the task of interest.\n",
    "\n",
    "\n",
    "You can think of the parameters as knobs that we can turn,\n",
    "manipulating the behavior of the program.\n",
    "Fixing a the parameters, we call the program a *model*.\n",
    "The set of all distinct programs (input-output mappings)\n",
    "that we can produce just by manipulating the parameters\n",
    "is called a *family* of models.\n",
    "And the *meta-program* that uses our dataset\n",
    "to choose the parameters is called a *learning algorithm*.\n",
    "\n",
    "\n",
    "Before we an go ahead and engage the learning algorithm,\n",
    "we have to define the problem precisely,\n",
    "pinning down the exact nature of the inputs and outputs,\n",
    "and choosing an appropriate model family.\n",
    "In this case, our model receives a snippet of audio as *input*,\n",
    "and it generates a selection among ``{yes, no}`` as *output*—which,\n",
    "if all goes according to plan,\n",
    "will closely approximate whether (or not)\n",
    "the snippet contains the wake word.\n",
    "\n",
    "If we choose the right family of models,\n",
    "then there should exist one setting of the knobs\n",
    "such that the model fires ``yes`` every time it hears the word 'Alexa'.\n",
    "Because the exact choice of the wake word is arbitrary,\n",
    "we'll probably need a model family capable, via another setting of the knobs,\n",
    "of firing ``yes`` on the word 'Apricot'.\n",
    "We expect that the same model should apply to 'Alexa' recognition and 'Apricot' recognition because these are similar tasks.\n",
    "However, we might need a different family of models entirely\n",
    "if we want to deal with fundamentally different inputs or outputs,\n",
    "say if we wanted to map from images to captions,\n",
    "or from English sentences to Chinese sentences.\n",
    "\n",
    "\n",
    "As you might guess, if we just set the knobs randomly,\n",
    "the model will probably recognize neither 'Alexa', 'Apricot',\n",
    "nor any other English word.\n",
    "Generally, in deep learning, the *learning*\n",
    "refers to updating the model's behavior (by tuning the knobs)\n",
    "over the course of a *training period*.\n",
    "\n",
    "The training process usually looks like this:\n",
    "\n",
    "1. Start off with a randomly initialized model that can't do anything useful.\n",
    "1. Grab some of your labeled data (e.g. audio snippets and corresponding ``{yes,no}`` labels)\n",
    "1. Tweak the knobs so the model sucks less with respect to those examples\n",
    "1. Repeat until the model is awesome.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/d2l-ai/notebooks/master/img/ml-loop.png\" alt=\"\" width=297 height=95/>\n",
    "\n",
    "\n",
    "\n",
    "To summarize, rather than code up a wake word recognizer,\n",
    "we code up a program that can *learn* to recognize wake words,\n",
    "*if we present it with a large labeled dataset*.\n",
    "You can think of this act\n",
    "of determining a program's behavior by presenting it with a dataset\n",
    "as *programming with data*.\n",
    "\n",
    "We can 'program' a cat detector by providing our machine learning system with many examples of cats and dogs, such as the images below:\n",
    "\n",
    "![](../img/cat1.png)|![](../img/cat2.jpg)|![](../img/dog1.jpg)|![](https://raw.githubusercontent.com/d2l-ai/notebooks/master/img/dog2.jpg)\n",
    "|:---------------:|:---------------:|:---------------:|:---------------:|\n",
    "|cat|cat|dog|dog|\n",
    "\n",
    "This way the detector will eventually learn to emit\n",
    "a very large positive number if it's a cat,\n",
    "a very large negative number if it's a dog,\n",
    "and something closer to zero if it isn't sure,\n",
    "and this barely scratches the surface of what ML can do.\n",
    "\n",
    "Deep learning is just one among many\n",
    "popular frameworks for building such model families.\n",
    "While thus far, we've only talked about machine learning broadly\n",
    "and not deep learning, there's a couple points worth sneaking in here:\n",
    "First, the problems that we've discussed thus far:\n",
    "learning from raw audio signal,\n",
    "directly from the pixels in images,\n",
    "and mapping between sentences of arbitrary lengths and across languages\n",
    "are problems where deep learning excels and traditional ML tools faltered.\n",
    "Deep models are *deep* in precisely the sense that they learn\n",
    "many *layers* of computation.\n",
    "It turns out that these many-layered (or hierarchical) models\n",
    "are capable of addressing low-level perceptual data\n",
    "in a way that previous tools could not.\n",
    "In bygone days, the crucial part of applying ML to these problems\n",
    "consisted of coming up with manually engineered ways of transforming\n",
    "the data into some form amenable to *shallow* models.\n",
    "One key advantage of deep learning is that it replaces not only the *shallow* models that lived at the end of traditional learning pipelines,\n",
    "but also the labor-intensive feature engineering.\n",
    "Secondly, by replacing by eliminating much of the *domain-specific preprocessing*,\n",
    "deep learning has eliminated many of the boundaries\n",
    "that previously separated computer vision, speech recognition, natural language processing, medical informatics, and other application areas,\n",
    "offering a unified set of tools for tackling diverse problems."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}